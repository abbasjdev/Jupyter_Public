{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Analysis of Supply Chain Data <br>\n",
    "##### By Abbas Jawad <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In this dataset, we will use data science tools to clean, analyze, interpret, and generate action plans accordingly. The purpose of this exercise is to showcase competencies in tools, contextualization, and insight generation. \n",
    "\n",
    "\n",
    "First, we will need to import all of the necessesary dependencies to aid in our workflow. \n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\Abbas Jawad\\.cache\\kagglehub\\datasets\\amirmotefaker\\supply-chain-dataset\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os #For operating System tayloring\n",
    "import kagglehub #For using library to download datasets directly from Kaggle API\n",
    "import pandas as pd #Commonly used library to analayze and visualize datasets\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"amirmotefaker/supply-chain-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will need to creaet a variable to pull the dataset from the allocated path in our local device. If statement implemented to for error-handling in path location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full file path: C:\\Users\\Abbas Jawad\\.cache\\kagglehub\\datasets\\amirmotefaker\\supply-chain-dataset\\versions\\1\\supply_chain_data.csv\n"
     ]
    }
   ],
   "source": [
    "csv_file_path = os.path.join(path, \"supply_chain_data.csv\")  \n",
    "print(\"Full file path:\", csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Product type   SKU      Price  Availability  Number of products sold  \\\n",
      "0     haircare  SKU0  69.808006            55                      802   \n",
      "1     skincare  SKU1  14.843523            95                      736   \n",
      "2     haircare  SKU2  11.319683            34                        8   \n",
      "3     skincare  SKU3  61.163343            68                       83   \n",
      "4     skincare  SKU4   4.805496            26                      871   \n",
      "\n",
      "   Revenue generated Customer demographics  Stock levels  Lead times  \\\n",
      "0        8661.996792            Non-binary            58           7   \n",
      "1        7460.900065                Female            53          30   \n",
      "2        9577.749626               Unknown             1          10   \n",
      "3        7766.836426            Non-binary            23          13   \n",
      "4        2686.505152            Non-binary             5           3   \n",
      "\n",
      "   Order quantities  ...  Location Lead time  Production volumes  \\\n",
      "0                96  ...    Mumbai        29                 215   \n",
      "1                37  ...    Mumbai        23                 517   \n",
      "2                88  ...    Mumbai        12                 971   \n",
      "3                59  ...   Kolkata        24                 937   \n",
      "4                56  ...     Delhi         5                 414   \n",
      "\n",
      "  Manufacturing lead time Manufacturing costs  Inspection results  \\\n",
      "0                      29           46.279879             Pending   \n",
      "1                      30           33.616769             Pending   \n",
      "2                      27           30.688019             Pending   \n",
      "3                      18           35.624741                Fail   \n",
      "4                       3           92.065161                Fail   \n",
      "\n",
      "   Defect rates  Transportation modes   Routes       Costs  \n",
      "0      0.226410                  Road  Route B  187.752075  \n",
      "1      4.854068                  Road  Route B  503.065579  \n",
      "2      4.580593                   Air  Route C  141.920282  \n",
      "3      4.746649                  Rail  Route A  254.776159  \n",
      "4      3.145580                   Air  Route A  923.440632  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "The total number of rows in this dataset is:  100\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(csv_file_path):  # os.path.exists requires os\n",
    "    # Load the CSV into a pandas DataFrame\n",
    "    data = pd.read_csv(csv_file_path, index_col=False, header=0)\n",
    "    print(data.head())  # Display the first 5 rows\n",
    "else:\n",
    "    print(\"The file was not found at the specified path.\")\n",
    "    \n",
    "    print(\"Full file path:\", csv_file_path)\n",
    "    \n",
    "    \n",
    "    \n",
    "num_rows = len(data)\n",
    "\n",
    "\n",
    "print(\"The total number of rows in this dataset is: \",num_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Once we have verified that the file path is in working order, we can begin with processing our data.\n",
    "\n",
    "Upon initial inspection, we can see the context of the data in the column headers.\n",
    "Additionally, we can tell that this dataset has exactly 100 entries (i.e.) rows in the dataset. \n",
    "Based on the 10 times rule (count of entries should be 10X more than count of parameters), we find that this dataset is a bit small for meaningful assessment. \n",
    "However, for the sake of the exercise, we will assume sufficiency. \n",
    "\n",
    "\n",
    "At first glance, we can determine that this is sales data based on product type, costs, availabliliy and demographics. \n",
    "\n",
    "This dataset can be used to make determinations on what factors have relevant contributions to target variables (i.e. dependent variables). \n",
    "For example, If I wanted to approximate what signifcantly contributes to the Number of Products Sold, I can make use of a logisitic regression model and \n",
    "determine the P-value of each dependent variable. \n",
    "\n",
    "We do this to filter out any insignicant variables and allocate our focus/resources to the variables that \"push the needle forward\".\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using OLS (Ordinary Least Squares) Model to determine how to predict number of products sold."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
